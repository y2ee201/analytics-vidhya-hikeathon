{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 70661802 entries, 0 to 70661801\n",
      "Data columns (total 3 columns):\n",
      "node1_id    int64\n",
      "node2_id    int64\n",
      "is_chat     int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 1.6 GB\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('./train/train.csv')\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 69758314 entries, 0 to 70661801\n",
      "Data columns (total 3 columns):\n",
      "node1_id    int64\n",
      "node2_id    int64\n",
      "is_chat     int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 2.1 GB\n"
     ]
    }
   ],
   "source": [
    "train = train[train.node1_id!=train.node2_id]\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8264276 entries, 0 to 8264275\n",
      "Data columns (total 14 columns):\n",
      "node_id    int64\n",
      "f1         int64\n",
      "f2         int64\n",
      "f3         int64\n",
      "f4         int64\n",
      "f5         int64\n",
      "f6         int64\n",
      "f7         int64\n",
      "f8         int64\n",
      "f9         int64\n",
      "f10        int64\n",
      "f11        int64\n",
      "f12        int64\n",
      "f13        int64\n",
      "dtypes: int64(14)\n",
      "memory usage: 882.7 MB\n"
     ]
    }
   ],
   "source": [
    "user_features = pd.read_csv('./train/user_features.csv')\n",
    "user_features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 69758314 entries, 0 to 69758313\n",
      "Data columns (total 26 columns):\n",
      "f1_x     int64\n",
      "f2_x     int64\n",
      "f3_x     int64\n",
      "f4_x     int64\n",
      "f5_x     int64\n",
      "f6_x     int64\n",
      "f7_x     int64\n",
      "f8_x     int64\n",
      "f9_x     int64\n",
      "f10_x    int64\n",
      "f11_x    int64\n",
      "f12_x    int64\n",
      "f13_x    int64\n",
      "f1_y     int64\n",
      "f2_y     int64\n",
      "f3_y     int64\n",
      "f4_y     int64\n",
      "f5_y     int64\n",
      "f6_y     int64\n",
      "f7_y     int64\n",
      "f8_y     int64\n",
      "f9_y     int64\n",
      "f10_y    int64\n",
      "f11_y    int64\n",
      "f12_y    int64\n",
      "f13_y    int64\n",
      "dtypes: int64(26)\n",
      "memory usage: 14.0 GB\n"
     ]
    }
   ],
   "source": [
    "base = train.merge(user_features, left_on='node1_id', right_on='node_id', how = 'left')\n",
    "base = base.merge(user_features, left_on='node2_id', right_on='node_id', how = 'left')\n",
    "base = base.drop(columns=['node_id_x', 'node_id_y','node1_id','node2_id'])\n",
    "y = base.is_chat\n",
    "base = base.drop(columns=['is_chat'])\n",
    "base.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69758314, 26)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "sc = RobustScaler()\n",
    "base = sc.fit_transform(base)\n",
    "base.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.pkl']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib \n",
    "\n",
    "joblib.dump(sc, 'scaler.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_l (InputLayer)            (None, 13)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_r (InputLayer)            (None, 13)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 13)           728         input_l[0][0]                    \n",
      "                                                                 input_r[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 1)            0           sequential_1[1][0]               \n",
      "                                                                 sequential_1[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "subtract_1 (Subtract)           (None, 13)           0           sequential_1[1][0]               \n",
      "                                                                 sequential_1[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 13)           0           sequential_1[1][0]               \n",
      "                                                                 sequential_1[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 27)           0           dot_1[0][0]                      \n",
      "                                                                 subtract_1[0][0]                 \n",
      "                                                                 lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 30)           840         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 30)           930         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 30)           930         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            31          dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 3,459\n",
      "Trainable params: 3,459\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, subtract, dot, merge, Input, concatenate, Lambda\n",
    "from keras.models import Model, Sequential\n",
    "\n",
    "# inputs = Input(shape=[26])\n",
    "# print(inputs.shape)\n",
    "\n",
    "input_l = Input(shape=[13], name='input_l')\n",
    "input_r = Input(shape=[13], name='input_r')\n",
    "# print(input_l.shape, input_r.shape)\n",
    "\n",
    "nn_siamese = Sequential()\n",
    "nn_siamese.add(Dense(13, activation = 'relu', name='siam_1'))\n",
    "nn_siamese.add(Dense(13, activation = 'relu', name='siam_2'))\n",
    "nn_siamese.add(Dense(13, activation = 'relu', name='siam_3'))\n",
    "nn_siamese.add(Dense(13, activation = 'relu', name='siam_4'))\n",
    "\n",
    "encoded_l = nn_siamese(input_l)\n",
    "encoded_r = nn_siamese(input_r)\n",
    "\n",
    "encoded_dot = dot([encoded_l, encoded_r], axes = 1)\n",
    "encoded_minus = subtract([encoded_l, encoded_r])\n",
    "encoded_func = Lambda(lambda tensor:K.abs(tensor[0] - tensor[1]))\n",
    "encoded_f1 = encoded_func([encoded_l, encoded_r])\n",
    "# print(encoded_dot.shape, encoded_minus.shape, encoded_f1.shape)\n",
    "\n",
    "encoded_concat = concatenate([encoded_dot, encoded_minus, encoded_f1])\n",
    "# print(encoded_concat.shape)\n",
    "\n",
    "dense = Dense(30, activation = 'relu')(encoded_concat)\n",
    "dense = Dense(30, activation = 'relu')(dense)\n",
    "dense = Dense(30, activation = 'relu')(dense)\n",
    "dense = Dense(1, activation = 'sigmoid')(dense)\n",
    "\n",
    "model = Model(inputs = [input_l, input_r], outputs = dense)\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', metrics = [auc], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "\n",
    "mc = ModelCheckpoint('hike_recommender_{epoch:02d}-{val_loss:.2f}.hdf5', monitor='val_loss', \n",
    "                     verbose=0, save_best_only=True, mode='auto', period=1)\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', patience=6, verbose=0, mode='auto', baseline=None, restore_best_weights=True)\n",
    "\n",
    "log = CSVLogger('training.csv', separator=',', append=True)\n",
    "\n",
    "rlr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)\n",
    "\n",
    "cbs = [mc, es, log]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55806651 samples, validate on 13951663 samples\n",
      "Epoch 1/50\n",
      "55806651/55806651 [==============================] - 1756s 31us/step - loss: 0.1142 - auc: 0.8219 - val_loss: 0.1132 - val_auc: 0.8296\n",
      "Epoch 2/50\n",
      "55806651/55806651 [==============================] - 2661s 48us/step - loss: 0.1120 - auc: 0.8322 - val_loss: 0.1128 - val_auc: 0.8341\n",
      "Epoch 3/50\n",
      "55806651/55806651 [==============================] - 1284s 23us/step - loss: 0.1115 - auc: 0.8351 - val_loss: 0.1116 - val_auc: 0.8360\n",
      "Epoch 4/50\n",
      "55806651/55806651 [==============================] - 3142s 56us/step - loss: 0.1112 - auc: 0.8366 - val_loss: 0.1109 - val_auc: 0.8373\n",
      "Epoch 5/50\n",
      " 7996672/55806651 [===>..........................] - ETA: 50:15:45 - loss: 0.1113 - auc: 0.8375"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-cf580d02c635>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m training_history = model.fit([base[:, 0:13], base[:, 13:]], y, epochs=50, \n\u001b[0;32m----> 2\u001b[0;31m                              batch_size=256, verbose = 1, validation_split=0.2, callbacks = cbs)\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/devenv/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/anaconda3/envs/devenv/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    185\u001b[0m                             ins[:-1], batch_ids) + [ins[-1]]\n\u001b[1;32m    186\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m                         \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m                     raise TypeError('TypeError while preparing batch. '\n",
      "\u001b[0;32m/anaconda3/envs/devenv/lib/python3.6/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mslice_arrays\u001b[0;34m(arrays, start, stop)\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/devenv/lib/python3.6/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_history = model.fit([base[:, 0:13], base[:, 13:]], y, epochs=50, \n",
    "                             batch_size=256, verbose = 1, validation_split=0.2, callbacks = cbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('./test.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
